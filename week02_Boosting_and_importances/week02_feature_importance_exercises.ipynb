{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5f86ae69cd2e64158e8b0fee959c61b3c50be21"
   },
   "source": [
    "## week02: Feature importances\n",
    "_based on kaggle tutorials:_\n",
    "* https://www.kaggle.com/neychev/exercise-shap-values\n",
    "* https://www.kaggle.com/neychev/exercise-advanced-uses-of-shap-values-14c76e\n",
    "\n",
    "\n",
    "We have again provided code to do the basic loading, review and model-building. Run the cell below to set everything up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Colab, uncomment this cell\n",
    "# ! pip install pdpbox\n",
    "# ! pip install eli5\n",
    "# ! pip install shap\n",
    "# ! wget https://raw.githubusercontent.com/neychev/fall19_madmo_adv/master/week02_Boosting_and_importances/data/medical.csv\n",
    "# ! mkdir data\n",
    "# ! mv medical.csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b7d092e3ee340cc466fe1b4babdf58f00eaed0c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/medical.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Scenario\n",
    "A hospital has struggled with \"readmissions,\" where they release a patient before the patient has recovered enough, and the patient returns with health complications. \n",
    "\n",
    "The hospital wants your help identifying patients at highest risk of being readmitted. Doctors (rather than your model) will make the final decision about when to release each patient; but they hope your model will highlight issues the doctors should consider when releasing a patient.\n",
    "\n",
    "The hospital has given you relevant patient medical information.  Here is a list of columns in the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc3d0c411fa91a9ff4dc7c987d3f384b7e0fb5ff"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some quick hints at interpreting the field names:\n",
    "\n",
    "- Your prediction target is `readmitted`\n",
    "- Columns with the word `diag` indicate the diagnostic code of the illness or illnesses the patient was admitted with. For example, `diag_1_428` means the doctor said their first illness diagnosis is number \"428\".  What illness does 428 correspond to? You could look it up in a codebook, but without more medical background it wouldn't mean anything to you anyway.\n",
    "- A column names like `glimepiride_No` mean the patient did not have the medicine `glimepiride`. If this feature had a value of False, then the patient did take the drug `glimepiride`\n",
    "- Features whose names begin with `medical_specialty` describe the specialty of the doctor seeing the patient. The values in these fields are all `True` or `False`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "You have built a simple model, but the doctors say they don't know how to evaluate a model, and they'd like you to show them some evidence the model is doing something in line with their medical intuition. Create any graphics or tables that will show them a quick overview of what the model is doing?\n",
    "\n",
    "They are very busy. So they want you to condense your model overview into just 1 or 2 graphics, rather than a long string of graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data.readmitted\n",
    "\n",
    "base_features = [c for c in data.columns if c != \"readmitted\"]\n",
    "\n",
    "X = data[base_features]\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "my_model = RandomForestClassifier(n_estimators=30, random_state=1).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use permutation importance as a succinct model summary\n",
    "# A measure of model performance on validation data would be useful here too\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\n",
    "eli5.show_weights(perm, feature_names = val_X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "It appears `number_inpatient` is a really important feature. The doctors would like to know more about that. Create a graph for them that shows how `num_inpatient` affects the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDP for number_inpatient feature\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "feature_name = 'number_inpatient'\n",
    "# Create the data that we will plot\n",
    "my_pdp = <YOUR CODE HERE>\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(my_pdp, feature_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "The doctors think it's a good sign that increasing the number of inpatient procedures leads to increased predictions.  But they can't tell from this plot whether that change in the plot is big or small. They'd like you to create something similar for `time_in_hospital` to see how that compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results are very different. Specifically time in hospital has a much smaller effect. Code below:\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "feature_name = 'time_in_hospital'\n",
    "# Create the data that we will plot\n",
    "my_pdp = <YOUR CODE HERE>\n",
    "\n",
    "# plot it\n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "Woah!  It seems like `time_in_hospital` doesn't matter at all.  The difference between the lowest value on the partial dependence plot and the highest value is about 5%.\n",
    "\n",
    "If that is what your model concluded, the doctors will believe it. But it seems so low. Could  the data be wrong, or is your model doing something more complex than they expect?  \n",
    "\n",
    "They'd like you to show them the raw readmission rate for each value of `time_in_hospital` to see how it compares to the partial dependence plot.\n",
    "\n",
    "- Make that plot. \n",
    "- Are the results similar or different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple pandas groupby showing the average readmission rate for each time_in_hospital.\n",
    "\n",
    "# Do concat to keep validation data separate, rather than using all original data\n",
    "all_train = pd.concat([train_X, train_y], axis=1)\n",
    "\n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "Now the doctors are convinced you have the right data, and the model overview looked reasonable.  It's time to turn this into a finished product they can use. Specifically, the hospital wants you to create a function `patient_risk_factors` that does the following\n",
    "- Takes a single row with patient data (of the same format you as your raw data)\n",
    "- Creates a visualization showing what features of that patient increased their risk of readmission, what features decreased it, and how much those features mattered.\n",
    "\n",
    "It's not important to show every feature with every miniscule impact on the readmission risk.  It's fine to focus on only the most important features for that patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SHAP values to show the effect of each feature of a given patient\n",
    "\n",
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "sample_data_for_prediction = val_X.iloc[0].astype(float)  # to test function\n",
    "\n",
    "def patient_risk_factors(model, patient_data):\n",
    "    # Create object that can calculate shap values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(patient_data)\n",
    "    shap.initjs()\n",
    "    return shap.force_plot(explainer.expected_value[1], shap_values[1], patient_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_risk_factors(my_model, val_X.iloc[5].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data/medical.csv')\n",
    "y = data.readmitted\n",
    "base_features = ['number_inpatient', 'num_medications', 'number_diagnoses', 'num_lab_procedures', \n",
    "                 'num_procedures', 'time_in_hospital', 'number_outpatient', 'number_emergency', \n",
    "                 'gender_Female', 'payer_code_?', 'medical_specialty_?', 'diag_1_428', 'diag_1_414', \n",
    "                 'diabetesMed_Yes', 'A1Cresult_None']\n",
    "\n",
    "# Some versions of shap package error when mixing bools and numerics\n",
    "X = data[base_features].astype(float)\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# For speed, we will calculate shap values on smaller subset of the validation data\n",
    "small_val_X = val_X.iloc[:150]\n",
    "my_model = RandomForestClassifier(n_estimators=30, random_state=1).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "610513d90b678fa1a3c0814250b120c5d453f14c"
   },
   "source": [
    "The first few questions require examining the distribution of effects for each feature, rather than just an average effect for each feature.  Run the following cell for a summary plot of the shap_values for readmission. It will take about 20 seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f09350ab88c0a354f15bd313c774bf6a35fab5e5"
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(my_model)\n",
    "shap_values = explainer.shap_values(small_val_X)\n",
    "\n",
    "shap.summary_plot(shap_values[1], small_val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b15eeeaea29b38c57f772724038f40555bb917a0"
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Which of the following features has a bigger range of effects on predictions (i.e. larger difference between most positive and most negative effect)\n",
    "- `diag_1_428` or\n",
    "- `payer_code_?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "623b69922a83b8ed8d5e8054bfbc1df221eea796"
   },
   "source": [
    "## Question 2\n",
    "\n",
    "Do you believe the range of effects sizes (distance between smallest effect and largest effect) is a good indication of which feature will have a higher permutation importance? Why or why not?  \n",
    "\n",
    "If the **range of effect sizes** measures something different from **permutation importance**: which is a better answer for the question \"Which of these two features does the model say is more important for us to understand when discussing readmission risks in the population?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1eb6e1dbef7d5f9f2720403e6ceedf1a6449acd6"
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Both `diag_1_428` and `payer_code_?` are binary variables, taking values of 0 or 1.\n",
    "\n",
    "From the graph, which do you think would typically have a bigger impact on predicted readmission risk:\n",
    "- Changing `diag_1_428` from 0 to 1\n",
    "- Changing `payer_code_?` from 0 to 1\n",
    "\n",
    "To save you scrolling, we have included a cell below to plot the graph again (this one runs quickly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9d128a63d7c52fc67c9c441fcb82f2816d616db6"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], small_val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e4424bdfda6f97991f5ed8b0dcd80ceadb892675"
   },
   "source": [
    "## Question 4\n",
    "\n",
    "Some features (like `number_inpatient`) have reasonably clear separation between the blue and pink dots. Other variables like `num_lab_procedures` have blue and pink dots jumbled together, even though the SHAP values (or impacts on prediction) aren't all 0.\n",
    "\n",
    "What do you think you learn from the fact that `num_lab_procedures` has blue and pink dots jumbled together? Once you have your answer, uncomment the line below to verify your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84ea05a7b751e61298c5ea86b2d1e79292fb93f0"
   },
   "source": [
    "## Question 5\n",
    "\n",
    "Consider the following SHAP contribution dependence plot. \n",
    "\n",
    "The x-axis shows `feature_of_interest` and the points are colored based on `other_feature`.\n",
    "\n",
    "![Imgur](https://i.imgur.com/zFdHneM.png)\n",
    "\n",
    "Is there an interaction between `feature_of_interest` and `other_feature`?  \n",
    "If so, does `feature_of_interest` have a more positive impact on predictions when `other_feature` is high or when `other_feature` is low?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbe58c556e04519a92ac6067ff162c2488cd91ba"
   },
   "source": [
    "## Question 6\n",
    "\n",
    "Review the summary plot for the readmission data by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abf56a319265a4ddea5ce6d4b2e4397bd7c5ca1e"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], small_val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f325b48753c86629549cde994fac19294a47d49e"
   },
   "source": [
    "1. Both **num_medications** and **num_lab_procedures** share that jumbling of pink and blue dots.\n",
    "\n",
    "Aside from `num_medications` having effects of greater magnitude (both more positive and more negative), it's hard to see[](http://) a meaningful difference between how these two features affect readmission risk.  Create the SHAP dependence contribution plots for each variable, and describe what you think is different between how these two variables affect predictions.\n",
    "\n",
    "As a reminder, here is the code you previously saw to create this type of plot.\n",
    "\n",
    "    shap.dependence_plot(feature_of_interest, shap_values[1], val_X)\n",
    "    \n",
    "And recall that your validation data is called `small_val_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79fd96914237e0c5dce847d2bd3ac4ab4bf0d570"
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot('num_medications' ,shap_values[1], small_val_X)\n",
    "shap.dependence_plot('num_lab_procedures' ,shap_values[1], small_val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f982846b4991198feec877ed3af6fcddc7acc17"
   },
   "source": [
    "## Congrats\n",
    "\n",
    "That's it!  Machine Learning models should not feel like black boxes any more, because you have the tools to inspect them and understand what they learn about the world. \n",
    "\n",
    "This is an excellent skill for debugging models, building trust, and learning insights to make better decisions. These techniques have revolutionized how I do data science, and I hope they do the same for you.\n",
    "\n",
    "Kaggle has a lot of [free datasets](https://www.kaggle.com/datasets) to try out. If you learn something interesting about the world, share your work [in this forum](https://www.kaggle.com/learn-forum/66354). World (and original author of this tutorial) is excited to see what you do with your new skills."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 research env",
   "language": "python",
   "name": "py3_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
